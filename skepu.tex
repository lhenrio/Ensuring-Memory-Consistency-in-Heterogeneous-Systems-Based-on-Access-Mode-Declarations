\section{Case study for overlapping array accesses: SkePU}

Skeletons are pre-defined generic program building blocks,
inspired by higher-order functions,
that implement certain frequently occurring patterns of
computation and dependences, for which efficient parallel
or platform-specific implementations might be available.
Skeletons can be parameterized in problem-specific'
(usually, sequential) code to generate executable functions
with parallel implementations that can be called like
any handwritten implementation.

SkePU \cite{Enmyren10,Ernstsson18} 
is a C++ based skeleton programming framework for heterogeneous systems.
It provides a number of general-purpose data-parallel skeletons
(generalized map, reduce, mapreduce, stencil, scan), each of
which has implementations (backends) for execution on one and multiple CPU cores, as
well as CUDA and OpenCL backends for execution on single and multiple GPUs.
While it is possible to enforce using a specific backend (and thus,
execution platform) for a skeleton call or even an entire program
run, SkePU provides autotuned backend selection, which automatically 
decides at runtime,
based on internal performance models for the current target system, 
where to best execute a 
skeleton call in order to optimize for time or energy. 

All (non-scalar) operands passed into or out of skeleton calls must be
SkePU data containers, which wrap C++ datatypes;
currently, extensions of STL \texttt{vector<...>}
and a \texttt{matrix} data type are provided.
Using iterators, SkePU skeleton calls can work on dense sub-arrays
defined by arbitrary index intervals.
The SkePU data containers, improved in their second generation for
CUDA devices \cite{Dastgeer-IJPP15}, intercept all single-element
or bulk accesses to the encapsulated C++ arrays and
internally perform coherent software caching of
accessed element subsets in non-shared device memories, 
using lazy data copying to avoid unnecessary data moves.
They also transparently optimize the memory management
by lazy deallocation of invalidated device copies of element
subsets and reusing such space of matching size for new copies.
A smart copying technique locates, for each (sub)array access, the 
subranges with valid copies nearest to the accessing device
and thereby optimizes data transfer times additionally,
also using direct device-to-device copying where applicable.


\vspace{1.4mm}
\noindent
{\em Implementation notes }
SkePU\footnote{SkePU source code and documentation: http://www.ida.liu.se/labs/pelab/skepu} 
is organized as a C++ source-to-source precompiler based on 
LLVM clang and an include library.
The part of the SkePU source code dealing with coherence in SkePU 
is very large, over 1500 lines of C++ code in total that are 
spread over several source files. Hence, 
the coherence-relevant code of SkePU is much less
localized, and it is also more complex than that of VectorPU
because SkePU works with a more complex coherence protocol
and the device type and number is not hardcoded but can be 
arbitrarily large (VectorPU implicitly assumes 1 CPU and 1 GPU).
% Some code occurs many times, e.g. in different
% access operators or for different container initializers.
%
% Part of the coherence code for overlapping array accesses
% is not nicely written (lack of comments, some warning comments
% about unfixed or untested corner cases)
% but otherwise seems to make sense to me.

Each SkePU data container stores all its elements in main memory,
referred to as the \emph{main copy} and
(part of) elements accessed in skeleton calls might also reside
in one or separate device memories, referred to as \emph{device copies}.
The container itself resides in main memory as all decisions
about operand data movement etc.\ before and after a skeleton call 
are made on CPU, regardless where the skeleton call will execute, 
hence container metadata such as the main copy coherence state 
and those of existing device copies are stored in main memory (only).

The coherence state of the main copy (in main memory) 
is, basically, represented by 2 boolean flags: 
\verb+m_valid+ (initialized to true in container constructors) and 
\verb+_noValidDeviceCopy+ (initalized to true), as described below.

Device copies are identified by pairs consisting of the
address of the first element accessed and the number of
elements accessed. 
Multiple device copies of the same array can overlap 
even on same device (if they are readonly)
and multiple copies can exist even with write access if their element ranges do not overlap.
%
Different from the main copy, the current coherence state of device copies 
is \emph{implicitly} modeled by their membership in lists
that are maintained in the container in main memory at runtime: 
\begin{itemize}
\item list of valid device copies on each device
\item list of modified (valid) device copies on each device with main copy not updated yet. See also Figure~\ref{fig:skepucoherence1}.
\end{itemize}

\begin{figure}
\begin{small}
\begin{verbatim}
template <typename T>
class Vector
{   ...
 private:
  T *m_data; // array of data elements
  mutable bool m_valid; // keep track if main copy is valid or not
  size_type m_size;
  mutable bool m_noValidDeviceCopy;
  ...
  mutable std::map<std::pair<T*, size_type>, device_pointer_type_cu>
                             m_deviceMemPointers_CU[MAX_GPU_DEVICES];
  // list of copies changed on device but not synced with host memory:
  mutable std::map<std::pair<T*, size_type>, device_pointer_type_cu>
                    m_deviceMemPointers_Modified_CU[MAX_GPU_DEVICES];
  ...
}
\end{verbatim}
%   size_type m_capacity;
%   bool m_deallocEnabled;
\end{small}

\vspace{-3mm}
\caption{\label{fig:skepucoherence1}The main data structures managing
  coherence in the SkePU \texttt{Vector} container implementation (file 
   \texttt{vector.hpp}).}
\end{figure}

The coherence protocol used is a variant of MSI, with 3 states for the main copy:
\begin{itemize}
\item M: exclusive owning for reading and writing by CPU.\\
         Flags \verb+m_valid==true+ and \verb+m_noValidDeviceCopy==true+.
\item S: shared for multiple readers.\\
         Flags \verb+m_valid==true+ and 
               \verb+m_noValidDeviceCopy==false+.
\item I: invalid in main memory.  Flag \verb+m_valid==false+.
\end{itemize}

Interestingly, it is not explicitly represented if only \emph{part} of 
the main copy is invalid while another part is still valid. 
This is implicit, by having the still valid parts not
being members of the list of modified device copies.
Read and write accesses to single container elements 
are internally distinguished between
by using a container proxy class.

% Code snippets: it should maybe not exceed one page.
% Some manual "inlining" and simplification of the source code
% will be necessary to make it readable.

Due to space limitations we can here only display a few selected 
snippets of the SkePU container coherence code to illustrate the mechanism.
Figures \ref{fig:skepucoherence1}--\ref{fig:skepucoherence3} show small
samples of (simplified) coherence-related
code from files \texttt{vector.hpp}, %\texttt{vector/vector.inl} 
 \texttt{vector/vector\_cu.inl} and \texttt{backend/device\_mem\_pointer\_cu}.

  
%\begin{figure}
%\begin{small}
%\begin{verbatim}
%// function updateDevice_CU manages container state for
%// read and write accesses on a CUDA device:
%
%if(m_noValidDeviceCopy)  m_noValidDeviceCopy = false;
%   
%typename std::map<std::pair< T*, size_type>, device_pointer_type_cu >::iterator result;
%std::pair< T*, size_type > key(start, numElements);
%typename std::map<std::pair< T*,size_type >, device_pointer_type_cu >::const_iterator %it;
%result = m_deviceMemPointers_CU[deviceID].find(key);
%device_pointer_type_cu tempCopy = NULL;
%if (result == m_deviceMemPointers_CU[deviceID].end()) {
%  //insert new, alloc mem and copy
%  tempCopy = ...
%  if (hasReadAccess(accessMode))
%     copyDataToAnInvalidDeviceCopy(tempCopy, deviceID, streamID);
%  result = m_deviceMemPointers_CU[deviceID].insert(
%    m_deviceMemPointers_CU[deviceID].begin(), std::make_pair(key,tempCopy));
%}
%else { //already exists but need to update contents:
%   tempCopy = result->second;
%   if (hasReadAccess(accessMode) && tempCopy->isCopyValid()==false)
%     // check whether the copy is invalid and we need to copy data:
%         copyDataToAnInvalidDeviceCopy(tempCopy, deviceID, streamID);
%}
%// Before returning, mark all other copies as invalid
%// if writing this copy and they are overlapping with this copy */
%if (hasWriteAccess(accessMode)) {
%  // add this copy to modified list:
%  m_deviceMemPointers_Modified_CU[deviceID].insert(
%    m_deviceMemPointers_Modified_CU[deviceID].begin(), std::make_pair(key,tempCopy));
%  m_valid = false;
%  // mark only local copies invalid. Each device will do that in
%  // multi-gpu execution for each single call. ...
%  if (markOnlyLocalCopiesInvalid) {  ... }
%  else { // Mark all overlapping copies from all devices as invalid:
%    for (int devID = 0; devID < MAX_GPU_DEVICES; ++devID) {
%      if (m_deviceMemPointers_CU[devID].empty()) // no copies...
%         continue;
%      for (it = m_deviceMemPointers_CU[devID].begin();
%           it != m_deviceMemPointers_CU[devID].end(); ++it) {
%        if (tempCopy != it->second && it->second->isCopyValid()
%            && tempCopy->doCopiesOverlap(it->second, true)) {
%          // this is possible considering gpu-gpu transfers and
%          // in some other cases e.g. map(v1 RW); ... map2(..., v1 W);
%          if (it->second->deviceDataHasChanged()) {
%   //                      assert(false); /*! TODO: fix this */
%                     /*!
%                     * if not fully overlapped then need to transfer as some data % should be written back to device memory
%                     * if fully overlapped then no need to update it as it is %overwritten in current copy...
%                     */
%                     if(it->second->doOverlapAndCoverFully(tempCopy) == false)
%                     {
%                        it->second->copyDeviceToHost();
%                     }
%
%                     /*! should delete this copy from this list as it needs not to be %updated back... */
%                     assert(m_deviceMemPointers_Modified_CU[devID].find(it->first) != %m_deviceMemPointers_Modified_CU[devID].end());
%                     m_deviceMemPointers_Modified_CU[devID].erase(m_deviceMemPointers_M%odified_CU[devID].find(it->first));
%                  }
%
%                  /*! mark copy invalid */
%                  it->second->markCopyInvalid();
%               }
%            }
%         }
%      }
%   }
%\end{verbatim}
%\end{small}

%\vspace*{-3mm}
%\caption{\label{fig:skepucoherence2}Selected coherence code from the SkePU vector container implementation, here for write accesses on a CUDA device, 
%in file \texttt{vector\_cu.inl}.}
%\end{figure}
  

% \begin{figure}
%\begin{small}
%\begin{verbatim}
%// from vector_proxy.inl:
%...
%//This is where values are being read:
%template <typename T>
%Vector<T>::proxy_elem::operator T&() const
%{
%   update(m_parent);
%   return m_parent.m_data[m_index];
%}
%
%//This is where values are being written:
%template <typename T>
%typename Vector<T>::proxy_elem& Vector<T>::proxy_elem::operator=(const proxy_elem& rhs)
%{
%   update(rhs.m_parent);
%   updateAndInvalidate(m_parent);
%   m_parent.m_data[m_index] = rhs.m_parent.m_data[rhs.m_index];
%   return *this;
%}
%\end{verbatim}
%\end{small}
%}
%
%\vspace*{-3mm}
%\caption{\label{fig:skepucoherence2a}Code excerpt from the SkePU proxy
% vector for single-element accesses of a vector (parent) .}
%\end{figure}
  
\begin{figure}
\begin{small}
\begin{verbatim}
// Read on CPU via [] operator:
template <typename T>
const T& Vector<T>::operator[](const size_type index) const
{
  // updateHost() inlined, calls updateHostCU() and sets m_valid:
  if (deviceID < 0) { // do it for all devices....
    for (deviceID = 0; deviceID < MAX_GPU_DEVICES; ++deviceID) {
      if (m_deviceMemPointers_Modified_CU[deviceID].empty())
        continue;
      for (it = m_deviceMemPointers_Modified_CU[deviceID].begin();
           it!=m_deviceMemPointers_Modified_CU[deviceID].end(); ++it)
        // At one point in time, there could be >1 valid
        // "modified" copy per each device for a container */
        it->second->copyDeviceToHost();
      m_deviceMemPointers_Modified_CU[deviceID].clear();
      ...
    }
  }
  else if (!m_deviceMemPointers_Modified_CU[deviceID].empty()) 
    ... similar, do it only for given deviceID
  m_valid = true;
  return m_data[index];
}
\end{verbatim}
\end{small}

\vspace*{-3mm}
\caption{\label{fig:skepucoherence2b}Coherence code excerpt from \texttt{vector.inl}
          handling certain element read accesses to a SkePU vector on CPU.}
\end{figure}
  
  
\begin{figure}
% // from device_mem_pointer_cu.h:
%
%  // Checks whether the copy passed as argument has a subset of elements range
%  // to the one that object points to:
%  template <typename T>
%  bool DeviceMemPointer_CU<T>::doOverlapAndCoverFully (
%                       DeviceMemPointer_CU<T> *otherCopy )
%  { if (m_hostDataPointer <= otherCopy->m_hostDataPointer
%         && (m_hostDataPointer + m_numElements)
%             >= (otherCopy->m_hostDataPointer + otherCopy->m_numElements) )
%        return true;
%      return false;
% }
%
%    // returns true if there exist any range (that needs to be written) that
%   // is overlapping to the otherCopy:
%   template <typename T>
%   bool DeviceMemPointer_CU<T>::doCopiesOverlap ( DeviceMemPointer_CU<T> *otherCopy,
%                                                  bool oneUnitCheck)
%   {
%     if (oneUnitCheck)
%        assert(m_numOfRanges == 1 && otherCopy->m_numOfRanges == 1);
%     if ...
%
\begin{small}
\begin{verbatim}
// creating new device copy: allocate space in device memory
// and store a pointer to some data in host memory.
  ...
  /*! ranges that should be checked for overlap with other copies */
  m_rangesToCompare[m_numOfRanges++] =
                   std::make_pair( m_hostDataPointer, m_numElements );
  m_deviceDataHasChanged = false;
  ...
...
// returns true if there exists any range (that needs to be written)
// that is overlapping to the otherCopy:
template <typename T>
bool DeviceMemPointer_CU<T>::doCopiesOverlap(
                                DeviceMemPointer_CU<T> *otherCopy,...)
{  ...
  if (m_numOfRanges < 1)
    return false;
  for(size_t i=0; i<m_numOfRanges; ++i) {
    T *hostDataPtr = m_rangesToCompare[i].first;
    size_t numElements = m_rangesToCompare[i].second;
    if (hostDataPtr >= otherCopy->m_hostDataPtr &&
        hostDataPtr < otherCopy->m_hostDataPtr+otherCopy->m_numElements)
      return true;
    if (otherCopy->m_hostDataPtr >= hostDataPtr &&
        otherCopy->m_hostDataPtr < hostDataPtr + numElements )
      return true;
   }
   return false;
 }
 // ... for further overlap test functions see device_mem_pointer_cu.h
\end{verbatim}
\end{small}
%
%   // Checks whether there exists some overlap between elements range covered by current copy to the one passed as argument.
%   template <typename T>
%   bool DeviceMemPointer_CU<T>::doRangeOverlap( T *hostDataPointer, size_t numElements)
%   {
%     if (m_hostDataPointer + m_numElements <= hostDataPointer ) return false;
%     if (hostDataPointer + numElements <= m_hostDataPointer ) return false;
%     return true;
%   }
%   ...
\caption{\label{fig:skepucoherence3}Selected coherence code from the SkePU vector container implementation, in file \texttt{device\_mem\_pointer\_cu.h}.}
\end{figure}

